\section{Conclusion}
% summarize the main contributions of the paper; summarize the experimental
% results; argue again for our novelty; discuss future directions
We proposed a two-layer hidden Markov model for MOOC student behavior
modeling in an unsupervised learning framework on large collections of
actions extracted from MOOC log data. This model is different from existing
methods in that it treats behavior patterns as a sequence of \emph{latent
states}, rather than assigning these states in a rule-based manner. It
captures the variable behaviors of students over time, and allows
analysis at different levels of granularity.

We showed that such a model does in fact capture meaningful behavior
patterns and produces descriptions of these behavior patterns that are easy
to interpret. We argued that it is important to capture student behavior
patterns with more sophisticated models than simple discrete distributions
over actions in order to capture information present in bigrams of actions
(or above). By varying the number of latent
states inferred, we showed that the model is flexible and can capture
patterns of differing levels of specificity in this way.  Finally, we
investigated whether we can detect differences in student behavior patterns
as they correlate with course performance. Specifically, we demonstrated
that high-performing students produce substantially different HMM
transition diagrams that tend to show longer concentration span in quiz-taking
and more active  forum participation as compared with the average students. 

\subsection{Future Work}

Although we only experimented with our model on two MOOCs, the model
is completely general and can be easily applied to analyze the log of any other
course to enable deep understanding of student behaviors as well as the correlations
of such behaviors and other variables such as grades. We plan to develop a MOOC log analysis
system based on the proposed model to both facilitate education research and 
help instructors improve course design. 

Specifically, our model can be used to produce an ordered list of latent states for each
student over time. Given these labeled sequences, we could correlate
course-wide drifts in these latent states with events in a course. For
example, we might be able to automatically discover difficult or confusing
parts of a course by noticing spikes in the distribution of students over
latent states over time.

Our model does not explicitly model drop-out like
\citet{Kizilcec:2013:LAK}, but doing so is an obvious extension. Our model
should be able to provide predictions of when a student is ``at risk'' for
dropping out under such an extension.

Currently, the model learns a transition matrix over the latent states that
is \emph{shared} across all students. It would be interesting to instead
learn a different latent state transition matrix for each individual
student, but keep the second-level Markov models shared. This would provide
the model with more flexibility which may be desirable itself, but would
also naturally result in a description of a student (via his or her HMM
transitions) that could be incorporated into existing supervised learning
techniques that try to predict student outcomes for understanding
which of the latent behavior patterns discovered by 2L-HMM are most predictive
of the performance of student learning. 

There is more recent work on better learning algorithms for mixtures of
Markov models~\citep{Gupta:2016:NIPS}. It would be worth exploring whether
the advances proposed in this and similar work can be applied to our model
to address some of the concerns surrounding our use of the EM algorithm for
our parameter estimation.
