\section{Related Work}

Our model is based heavily upon the prior art of Hidden Markov
Models~\cite{Rabiner:1990:RSR} for sequence labeling tasks. These types of
models are widely applicable and have been used for tasks such as speech
recognition~\cite{Huang:1990:HMM} and part-of-speech
tagging~\cite{Jurafsky:2009:SLP}. A major challenge in applying HMMs successful to solve a problem is to design an appropriate architecture of the model, which always varies according to specific applications. 

HMMs or similar ideas have been previously 
applied to model education data~\cite{Shih:2010:EDM,Kizilcec:2013:LAK}, but the previous models are not well tuned toward the student behavior task and thus cannot
adequately address all the aspects of complexity of student learning behavior. 
A main technical contribution of this paper is to propose a more general
HMM that can better adapt to the variations of student behavior via its variable resolution
and nested HMM structure, and thus enable discovery of more sophisticated behavior patterns and provide more detailed characterization of student behavior than the previous models.
 
For example, \citet{Kizilcec:2013:LAK} assigned students to states following a rule-based
approach based upon when the student submitted the assignment for a
particular week in the course. They investigated how students transitioned
between these states as the course progressed, and used the sequence of
states a student exhibited as a representation for performing $k$-means
clustering of students into related groups. This differs from our method
substantially: we assign students to states using a probabilistic
framework to account for uncertainty in this state assignment, and jointly
learn representations for these states, which are treated as being
\emph{latent} as opposed to pre-definied using some rule (or set of rules).
Furthermore, our model provides more flexibility in how the time segments
are defined, allowing for both finer (for example, day-by-day) or courser
(for example, month-by-month) granularity. \citet{Shih:2010:EDM} investigated the use of HMM-based clustering
techniques for automatic discovery of student learning strategies when
solving a particular problem. This is similar to our approach in that the
description of behavior profiles is a Markov model, but cannot further characterize
each latent state with another informative HMM. Thus their work can be regarded
to modeling ``micro'' behavior, whereas our model can model both ``micro'' and ``macro'' behavior. 

\citet{Faucon:2016:EDM} proposed a semi-Markov model for simulating MOOC
students. They produce behavior profiles that characterize groups of
students in the form of semi-Markov models like our proposed model does,
but they differ from our work in two major ways. First, they assume that a
student can belong to only one behavior profile across the entire course
rather than allowing this profile to change over time.  Because we do not
have this restriction, our model is also able to learn the transition
probabilities between the different behavior profiles we discover.

There a few additional related studies worth mentioning.
Bayesian Knowledge Tracing~\cite{Corbett:1994:UMUAI} in its basic form uses
a hidden Markov model to model the probability that a learner knows a
certain skill at a given time. Modifications to this algorithm include
contextual estimation of the ``slip'' and ``guess'' probabilities of the
model~\cite{Baker:2008:ITS} and most recently a re-framing as a neural
network problem~\cite{Piech:2015:NIPS}.
\citet{Ypma:2002:Springer} use mixtures of HMMs to categorize web pages and
cluster users by investigating web log data, which is quite similar to the
clickstream log data we obtain from MOOCs.

