\section{A Two-Layer HMM for MOOC Log Analysis}

\begin{margintable}
  \vspace{-4.7in}
  \begin{center}
    \begin{tabular}{rr}
      \multicolumn{2}{c}{\textbf{\textretrieval{}}}\\\hline
      Students & 18,941\\
      Sequences & 85,240\\
      Avg. Len. & 7.31
    \end{tabular}
    \caption{Statistics about the sequences extracted from the MOOC.}
    \label{table:datasets}
  \end{center}
\end{margintable}

\marginpar{%
  \vspace{-1.6in}
  Each sequence is comprised of the following actions:
  \begin{enumerate}[itemsep=0,align=left,leftmargin=*]
    \item quiz start,
    \item quiz submit,
    \item wiki (course material),
    \item forum list (view the list of all forums),
    \item forum thread list (view the list of all threads in a specific
      forum),
    \item forum thread view (view the list of posts within a specific
      thread),
    \item forum search (a search query issued against the forum),
    \item forum post thread (a new thread was posted),
    \item forum post reply (a new post was created within an existing
      thread), and
    \item view lecture (defined as either streaming or downloading a lecture
      video).
  \end{enumerate}
}

Our general idea is to use a probabilistic generative model to model the
student activities as recorded in a MOOC log, which means we will assume
that all the observed student activities are samples drawn (i.e.,
``generated'') from a parameterized probabilistic model. We can then
estimate the parameter values of the probabilistic model by fitting the
model to a specific MOOC log data set. The estimated parameter values could
then be treated as the latent ``knowledge'' discovered from the data.
Because such a generative model attempts to fit {\em all} the data, it
enables us to discover interesting patterns that can explain the {\em
overall} behavior of a student or the {\em common} behavior patterns shared
by many students.

An HMM is a specific probabilistic generative model with a ``built-in''
state transition system that would control the data to be generated by the
model, thus it is especially suitable for modeling sequence
data. We may say that students transition through different ``task states''
(or ``behavior states'')  in the process of study.  One such task state may
be to learn about a topic by mostly watching lecture videos, another task
state may be to work on quizzes, and yet another may be to participate in
forum discussions. While in each of these different states, the student
would tend to exhibit different surface ``micro'' behaviors.  For example,
in the lecture study state, the student would tend to have many
video-watching related behaviors and occasionally forum activities, while
in the quiz-taking state, the student would tend to show many quiz-related
``micro'' activities as well as asking questions or checking discussions on
the forum.

The most natural application of an HMM to analyze our data would treat each
latent state as having a discrete distribution over the surface ``micro''
behaviors, but this only gives a rather superficial characterization of the
student behavior. Instead, we want to directly characterize the transitions
between the ``micro'' actions, so we treat an {\em entire
sequence} of micro activities (e.g., one session of activities) as an
observed ``symbol'' from a latent state, and further model the generation
of such a sequence with another Markov model where we treat each micro
activity as an {\em observable} state, and model the transitions between
these activity states in very much the same way as the state transitions in
HMM. Adding this second layer would allow us to characterize a latent task
state in much more detail, as it would reveal not only what activities are
most common to a task state, but also the transition patterns between these
activities.
